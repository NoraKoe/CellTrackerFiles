{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*note, not passing in kid info...model has trained right...so...*\n",
    "1) get the data to pass through...in one \"batch\" = pair of frames, for now you need to do comparisons iterating from frame i+1 to i, and run through less if a positive comes up already... - get the label pairs/store the batch info for cost matrix after model - batch lengths will vary, this can be super large for larger raws, so need to come up with some radius function...Jaqaman paper ideas\n",
    "2) form the data, including the appearances and the centroids to be able to be run with .predict\n",
    "3)...cost matrix?!?!? for hela, 30 labels is safe, needs to be set somehow...ah the matrices will all be square :)\n",
    "4) interpret output into cost matrix...the cost matrix needs to be ratio 1:2 (...there is issue rn with the padding for more than number of cells, which will be specific to sets based on if we are able to connect back annotated segments or really how large our testing raws are (compared to annotated...also how will we get the equivalent data with new data...deepcell, celltk...)\n",
    "5) ...tracking algorithm (relabelling b/w each frame pair using cost matrix...) - compare tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.activations import softmax\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Add, Permute, Input, Concatenate, concatenate\n",
    "from tensorflow.python.keras.layers import Conv2D, Conv3D, MaxPool2D, AvgPool2D\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.layers import Activation, Softmax\n",
    "from tensorflow.python.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "\n",
    "def siamese_model(input_shape=None, batch_shape=None, reg=1e-5, init='he_normal', permute=False, softmax=True, norm_method='std', filter_size=61):\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    input_1 = Input(shape=input_shape)\n",
    "    input_2 = Input(shape=input_shape)\n",
    "    input_3 = Input(shape=(2, ))\n",
    "    input_4 = Input(shape=(2, ))\n",
    "    \n",
    "    # Sequential interface for siamese portion of model\n",
    "    feature_extractor = Sequential()\n",
    "    feature_extractor.add(Conv2D(64, (3, 3), kernel_initializer=init, padding='same', kernel_regularizer=l2(reg), input_shape=input_shape))\n",
    "    feature_extractor.add(BatchNormalization(axis=channel_axis))\n",
    "    feature_extractor.add(Activation('relu'))\n",
    "    feature_extractor.add(Conv2D(64, (3, 3), kernel_initializer=init, padding='same', kernel_regularizer=l2(reg)))\n",
    "    feature_extractor.add(BatchNormalization(axis=channel_axis))\n",
    "    feature_extractor.add(Activation('relu'))\n",
    "    feature_extractor.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    feature_extractor.add(Conv2D(64, (3, 3), kernel_initializer=init, padding='same', kernel_regularizer=l2(reg)))\n",
    "    feature_extractor.add(BatchNormalization(axis=channel_axis))\n",
    "    feature_extractor.add(Activation('relu'))\n",
    "    feature_extractor.add(Conv2D(64, (3, 3), kernel_initializer=init, padding='same', kernel_regularizer=l2(reg)))\n",
    "    feature_extractor.add(BatchNormalization(axis=channel_axis))\n",
    "    feature_extractor.add(Activation('relu'))\n",
    "    feature_extractor.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Create two instances of feature_extractor\n",
    "    output_1 = feature_extractor(input_1)\n",
    "    #merged_output1 = concatenate([output_1, input_3], axis=channel_axis)\n",
    "    ##gmp_1 = GlobalMaxPooling2D()(output1)\n",
    "    ##gmp_2 = GlobalMaxPooling2D()(input_3)\n",
    "    ##merged_output1 = concatenate([gmp_1, gmp_2])\n",
    "    \n",
    "    output_2 = feature_extractor(input_2)\n",
    "    #merged_output2 = concatenate([output_2, input_4], axis=channel_axis)\n",
    "\n",
    "    flat1 = Flatten()(output_1)\n",
    "    flat2 = Flatten()(output_2)\n",
    "    #flat3 = Flatten()(input_3)\n",
    "    #flat4 = Flatten()(input_4)\n",
    "    merge_1 = concatenate([flat1, input_3])\n",
    "    merge_2 = concatenate([flat2, input_4])\n",
    "    # Concatenate outputs from both feature_extractor instances\n",
    "    \"\"\"\n",
    "    merged_outputs = Concatenate(axis=channel_axis)([output_1, output_2])\n",
    "    flat1 = Flatten()(merged_outputs)\n",
    "    distance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(input_3, input_4))))\n",
    "    print(distance, \"     type:\", type(distance))\n",
    "    merge_dist = concatenate([flat1, distance])\n",
    "    \"\"\"\n",
    "    merged_outputs = Concatenate(axis=channel_axis)([merge_1, merge_2])\n",
    "    # Implement dense net (or call preexisting one?) with the two outputs as inputs\n",
    "    #dense1 = Dense(128)(merge_dist)\n",
    "    dense1 = Dense(128)(merged_outputs)\n",
    "    bn1 = BatchNormalization(axis=channel_axis)(dense1)\n",
    "    relu1 = Activation('relu')(bn1)\n",
    "    dense2 = Dense(128)(relu1)\n",
    "    bn2 = BatchNormalization(axis=channel_axis)(dense2)\n",
    "    relu2 = Activation('relu')(bn2)\n",
    "    dense3 = Dense( 3, activation='softmax')(relu2) # changed to 3...\n",
    "\n",
    "    # Instantiate model\n",
    "    final_layer = dense3\n",
    "    model = Model(inputs=[input_1, input_2, input_3, input_4], outputs=final_layer)\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepcell.losses import categorical_crossentropy\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from deepcell.utils import rate_scheduler\n",
    "def train_model_siamese_daughter(model=None, dataset=None, optimizer=None,\n",
    "                        expt='', it=0, batch_size=1, n_epoch=100,\n",
    "                        direc_save='/data/models', direc_data='/data/npz_data',\n",
    "                        lr_sched=rate_scheduler(lr=0.01, decay=0.95),\n",
    "                        rotation_range=0, flip=True, shear=0, class_weight=None):\n",
    "    CHANNELS_FIRST = False\n",
    "    training_data_file_name = os.path.join(direc_data, dataset + '.npz')\n",
    "    todays_date = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    file_name_save = os.path.join(direc_save, '{}_{}_{}_{}.h5'.format(todays_date, dataset, expt, it))\n",
    "    file_name_save_loss = os.path.join(direc_save, '{}_{}_{}_{}.npz'.format(todays_date, dataset, expt, it))\n",
    "\n",
    "    train_dict, (X_test, y_test) = get_data(training_data_file_name, mode='siamese_daughters')\n",
    "\n",
    "    class_weights = train_dict['class_weights']\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    print('X_train shape:', train_dict['X'].shape)\n",
    "    print('y_train shape:', train_dict['y'].shape)\n",
    "    print('X_test shape:', X_test.shape)\n",
    "    print('y_test shape:', y_test[0].shape)\n",
    "    print('Output Shape:', model.layers[-1].output_shape)\n",
    "\n",
    "    n_classes = model.layers[-1].output_shape[1 if CHANNELS_FIRST else -1]\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    print('Using real-time data augmentation.')\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = SiameseDataGenerator(\n",
    "        rotation_range=rotation_range,  # randomly rotate images by 0 to rotation_range degrees\n",
    "        shear_range=shear, # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "        horizontal_flip=flip,  # randomly flip images\n",
    "        vertical_flip=flip)  # randomly flip images\n",
    "\n",
    "    datagen_val = SiameseDataGenerator(\n",
    "        rotation_range=0,  # randomly rotate images by 0 to rotation_range degrees\n",
    "        shear_range=0, # randomly shear images in the range (radians , -shear_range to shear_range)\n",
    "        horizontal_flip=0,  # randomly flip images\n",
    "        vertical_flip=0)  # randomly flip images\n",
    "\n",
    "    validation_dict = {'X': X_test, 'y': y_test[0], 'daughters': y_test[1]}\n",
    "\n",
    "    def count_pairs(y):\n",
    "        \"\"\"\n",
    "        Compute number of training samples needed to (stastically speaking)\n",
    "        observe all cell pairs.\n",
    "        Assume that the number of images is encoded in the second dimension.\n",
    "        Assume that y values are a cell-uniquely-labeled mask.\n",
    "        Assume that a cell is paired with one of its other frames 50% of the time\n",
    "        and a frame from another cell 50% of the time.\n",
    "        \"\"\"\n",
    "        # TODO: channels_first axes\n",
    "        total_pairs = 0\n",
    "        for image_set in range(y.shape[0]):\n",
    "            set_cells = 0\n",
    "            cells_per_image = []\n",
    "            for image in range(y.shape[1]):\n",
    "                image_cells = int(y[image_set, image, :, :, :].max())\n",
    "                set_cells = set_cells + image_cells\n",
    "                cells_per_image.append(image_cells)\n",
    "\n",
    "            # Since there are many more possible non-self pairings than there are self pairings,\n",
    "            # we want to estimate the number of possible non-self pairings and then multiply\n",
    "            # that number by two, since the odds of getting a non-self pairing are 50%, to\n",
    "            # find out how many pairs we would need to sample to (statistically speaking)\n",
    "            # observe all possible cell-frame pairs.\n",
    "            # We're going to assume that the average cell is present in every frame. This will\n",
    "            # lead to an underestimate of the number of possible non-self pairings, but it's\n",
    "            # unclear how significant the underestimate is.\n",
    "            average_cells_per_frame = int(sum(cells_per_image) / len(cells_per_image))\n",
    "            non_self_cellframes = (average_cells_per_frame - 1) * len(cells_per_image)\n",
    "            non_self_pairings = non_self_cellframes * max(cells_per_image)\n",
    "            cell_pairings = non_self_pairings * 2\n",
    "            total_pairs = total_pairs + cell_pairings\n",
    "        return total_pairs\n",
    "\n",
    "    # This shouldn't remain long term.\n",
    "    #magic_number = 2048  # A power of 2 chosen just to reduce training time.\n",
    "    total_train_pairs = count_pairs(train_dict['y'])\n",
    "    print(\"total_train_pairs:\", total_train_pairs)\n",
    "    #total_train_pairs = int(total_train_pairs // magic_number)\n",
    "    #print(\"total_train_pairs:\", total_train_pairs)\n",
    "\n",
    "    total_test_pairs = count_pairs(y_test[0])\n",
    "    #print(\"total_test_pairs:\", total_test_pairs)\n",
    "    #total_test_pairs = int(total_test_pairs // magic_number)\n",
    "    print(\"total_test_pairs:\", total_test_pairs)\n",
    "    print(\"batch size: \", batch_size)\n",
    "    print(\"validation_steps: \", total_test_pairs // batch_size)\n",
    "    test_1, test_2 = datagen.flow(train_dict, batch_size=batch_size, crop_dim=32).next()\n",
    "\n",
    "\n",
    "    \n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    loss_history = model.fit_generator(\n",
    "        datagen.flow(train_dict, batch_size=batch_size, crop_dim=32),\n",
    "        steps_per_epoch=total_train_pairs // batch_size,\n",
    "        epochs=n_epoch,\n",
    "        validation_data=datagen_val.flow(validation_dict, batch_size=batch_size, crop_dim=32),\n",
    "        validation_steps=total_test_pairs // batch_size,\n",
    "        callbacks=[\n",
    "            ModelCheckpoint(file_name_save, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
    "            LearningRateScheduler(lr_sched)\n",
    "        ])\n",
    "\n",
    "    model.save_weights(file_name_save)\n",
    "    np.savez(file_name_save_loss, loss_history=loss_history.history)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_inputs(X, y, frames, labels, crop_dim=14, data_format=\"channels_last\"): #labels as a tuple....while loop...\n",
    "    if data_format == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        appearance_shape = (X.shape[channel_axis], len(frames), crop_dim, crop_dim)\n",
    "    elif data_format == 'channels_last':\n",
    "        channel_axis = 3\n",
    "        appearance_shape = (len(frames), crop_dim, crop_dim, X.shape[channel_axis])\n",
    "    \n",
    "    #inputs = []\n",
    "    appearances = np.zeros(appearance_shape, dtype=K.floatx())\n",
    "    print(\"appearances: \", appearances.shape)\n",
    "    centroids = []\n",
    "    for counter, (frame, cell_label) in enumerate(zip(frames, labels)):\n",
    "        # Get the bounding box\n",
    "        y_frame = y[frame] if data_format == 'channels_last' else y[:, frame]\n",
    "        props = regionprops(np.uint8(y_frame == cell_label))\n",
    "        minr, minc, maxr, maxc = props[0].bbox\n",
    "        centroids.append(props[0].centroid)\n",
    "        \n",
    "        # Extract images from bounding boxes\n",
    "        if data_format == 'channels_first':\n",
    "            appearance = X[:, frame, minr:maxr, minc:maxc]\n",
    "            resize_shape = (X.shape[channel_axis], crop_dim, crop_dim)\n",
    "        else:\n",
    "            appearance = X[frame, minr:maxr, minc:maxc, :]\n",
    "            resize_shape = (crop_dim, crop_dim, X.shape[channel_axis])\n",
    "\n",
    "        # Resize images from bounding box\n",
    "        max_value = np.amax([np.amax(appearance), np.absolute(np.amin(appearance))])\n",
    "        appearance /= max_value\n",
    "        appearance = resize(appearance, resize_shape)\n",
    "        appearance *= max_value\n",
    "        #appearance.shape = (32, 32, 1)\n",
    "        #inputs.append(appearance)\n",
    "        if data_format == 'channels_first':\n",
    "            appearances[:, counter] = appearance\n",
    "        else:\n",
    "            appearances[counter] = appearance\n",
    "    #inputs.append(appearances)\n",
    "    #inputs.extend(centroids)\n",
    "    if data_format == 'channels_first':\n",
    "        img_shape = (2, X.shape[channel_axis], crop_dim, crop_dim) # passing in pair of images at a time...\n",
    "    else:\n",
    "        img_shape = (2, crop_dim, crop_dim, X.shape[channel_axis])\n",
    "        \n",
    "    data_shape = (2, 2,) # shape of centroid data\n",
    "\n",
    "    batch_x_1 = np.zeros(img_shape, dtype=K.floatx())\n",
    "    batch_x_2 = np.zeros(img_shape, dtype=K.floatx())\n",
    "    centroid_1 = np.zeros(data_shape, dtype=K.floatx())\n",
    "    centroid_2 = np.zeros(data_shape, dtype=K.floatx())\n",
    "    \n",
    "    batch_x_1[0] = appearances[0]\n",
    "    batch_x_2[0] = appearances[1]\n",
    "    \n",
    "    centroid_1[0] = np.array(centroids[0])\n",
    "    centroid_2[0] = np.array(centroids[1])\n",
    "\n",
    "    return [batch_x_1, batch_x_2, centroid_1, centroid_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "def run_model_siamese():\n",
    "    direc_data = '/data/npz_data/cells/HeLa/S3/movie/'\n",
    "    dataset = 'nuclear_movie_hela1_same'\n",
    "    #direc_data = 'C:\\\\Users\\\\Nora\\\\Desktop\\\\'\n",
    "    #dataset = 'nuclear_movie_hela1_same'\n",
    "    data = np.load('{}{}.npz'.format(direc_data, dataset))\n",
    "    segment = 0 #batch\n",
    "    first_f = 0\n",
    "    second_f = first_f+1\n",
    "    labels_in_second = np.uint8(np.unique(data['y'][segment][second_f])) # from annotation\n",
    "    labels_in_second = np.delete(labels_in_second, np.where(labels_in_second==0))\n",
    "    labels_in_first = np.uint8(np.unique(data['y'][segment][first_f])) # from annotation\n",
    "    labels_in_first = np.delete(labels_in_first, np.where(labels_in_first==0))\n",
    "    \n",
    "    compairs = []\n",
    "    for label in labels_in_second:\n",
    "        for y in labels_in_first:\n",
    "            compairs.append([y, label]) #while loop with flag to avoid checking for additional positives\n",
    "    print(compairs)\n",
    "\n",
    "    \"\"\"model\"\"\"\n",
    "    model_fn = siamese_model\n",
    "    model_name = \"2018-08-06_nuclear_movie_hela0_same__0.h5\"\n",
    "    MODEL_DIR = \"/data/models\"\n",
    "    PREFIX = \"cells/HeLa/S3/\"\n",
    "    in_shape = (32, 32, 1)\n",
    "    weights = os.path.join(MODEL_DIR, PREFIX, model_name)\n",
    "    #n_features = 3...not used?!\n",
    "    #window_size = (30, 30)\n",
    "\n",
    "    run_siamese_model = model_fn(input_shape=in_shape)\n",
    "    run_siamese_model.load_weights(weights)\n",
    "    print(\"weights loaded :)\")\n",
    "    \n",
    "    model_outputs = []\n",
    "\n",
    "    for i in range(len(compairs)):\n",
    "        print(\"label list: \", compairs[i])\n",
    "        into_model = get_inputs(data['X'][segment], data['y'][segment], [first_f, second_f], compairs[i], crop_dim = 32)\n",
    "        \n",
    "        model_output = run_siamese_model.predict(into_model)\n",
    "        print(\"output: \", model_output.shape)\n",
    "        print(model_output)\n",
    "        model_outputs.append(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1], [2, 1], [3, 1], [4, 1], [5, 1], [6, 1], [7, 1], [8, 1], [9, 1], [10, 1], [1, 2], [2, 2], [3, 2], [4, 2], [5, 2], [6, 2], [7, 2], [8, 2], [9, 2], [10, 2], [1, 3], [2, 3], [3, 3], [4, 3], [5, 3], [6, 3], [7, 3], [8, 3], [9, 3], [10, 3], [1, 4], [2, 4], [3, 4], [4, 4], [5, 4], [6, 4], [7, 4], [8, 4], [9, 4], [10, 4], [1, 5], [2, 5], [3, 5], [4, 5], [5, 5], [6, 5], [7, 5], [8, 5], [9, 5], [10, 5], [1, 6], [2, 6], [3, 6], [4, 6], [5, 6], [6, 6], [7, 6], [8, 6], [9, 6], [10, 6], [1, 7], [2, 7], [3, 7], [4, 7], [5, 7], [6, 7], [7, 7], [8, 7], [9, 7], [10, 7], [1, 8], [2, 8], [3, 8], [4, 8], [5, 8], [6, 8], [7, 8], [8, 8], [9, 8], [10, 8], [1, 9], [2, 9], [3, 9], [4, 9], [5, 9], [6, 9], [7, 9], [8, 9], [9, 9], [10, 9], [1, 10], [2, 10], [3, 10], [4, 10], [5, 10], [6, 10], [7, 10], [8, 10], [9, 10], [10, 10]]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 8, 8, 64)     112448      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4096)         0           sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4096)         0           sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4098)         0           flatten_1[0][0]                  \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4098)         0           flatten_2[0][0]                  \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8196)         0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          1049216     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 3)            387         activation_6[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,179,587\n",
      "Trainable params: 1,178,563\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "weights loaded :)\n",
      "label list:  [1, 1]\n",
      "appearances:  (2, 32, 32, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "run_model_siamese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, if you scroll down, you can see that the images passed out of the input function are correct,\n",
    "# but that the model output is the same as the first "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# disregard below this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 216, 256, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment = 0 #batch\n",
    "first_f = 0\n",
    "second_f = first_f+1\n",
    "data['X'][segment].shape # segment 0_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 256, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['X'][segment][first_f].shape # frame 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 256, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['X'][segment][second_f].shape # frame 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "labels_in_second = np.uint8(np.unique(data['y'][segment][second_f])) # from annotation\n",
    "labels_in_second = np.delete(labels_in_second, np.where(labels_in_second==0))\n",
    "print(labels_in_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "labels_in_first = np.uint8(np.unique(data['y'][segment][first_f])) # from annotation\n",
    "labels_in_first = np.delete(labels_in_first, np.where(labels_in_first==0))\n",
    "print(labels_in_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import regionprops\n",
    "from skimage.transform import resize\n",
    "\n",
    "def get_inputs(X, y, frames, labels, crop_dim=14, data_format=\"channels_last\"): #labels as a tuple....while loop...\n",
    "    if data_format == 'channels_first':\n",
    "        channel_axis = 1\n",
    "        appearance_shape = (X.shape[channel_axis], len(frames), crop_dim, crop_dim)\n",
    "    elif data_format == 'channels_last':\n",
    "        channel_axis = 3\n",
    "        appearance_shape = (len(frames), crop_dim, crop_dim, X.shape[channel_axis])\n",
    "    \n",
    "    #inputs = []\n",
    "    appearances = np.zeros(appearance_shape, dtype=K.floatx())\n",
    "    print(\"appearances: \", appearances.shape)\n",
    "    centroids = []\n",
    "    for counter, (frame, cell_label) in enumerate(zip(frames, labels)):\n",
    "        # Get the bounding box\n",
    "        y_frame = y[frame] if data_format == 'channels_last' else y[:, frame]\n",
    "        props = regionprops(np.uint8(y_frame == cell_label))\n",
    "        minr, minc, maxr, maxc = props[0].bbox\n",
    "        centroids.append(props[0].centroid)\n",
    "        \n",
    "        # Extract images from bounding boxes\n",
    "        if data_format == 'channels_first':\n",
    "            appearance = X[:, frame, minr:maxr, minc:maxc]\n",
    "            resize_shape = (X.shape[channel_axis], crop_dim, crop_dim)\n",
    "        else:\n",
    "            appearance = X[frame, minr:maxr, minc:maxc, :]\n",
    "            resize_shape = (crop_dim, crop_dim, X.shape[channel_axis])\n",
    "\n",
    "        # Resize images from bounding box\n",
    "        max_value = np.amax([np.amax(appearance), np.absolute(np.amin(appearance))])\n",
    "        appearance /= max_value\n",
    "        appearance = resize(appearance, resize_shape)\n",
    "        appearance *= max_value\n",
    "        #appearance.shape = (32, 32, 1)\n",
    "        #plt.imshow(appearance[:,:,0]) # 1, :, 0\n",
    "        #inputs.append(appearance)\n",
    "        if data_format == 'channels_first':\n",
    "            appearances[:, counter] = appearance\n",
    "        else:\n",
    "            appearances[counter] = appearance\n",
    "    #inputs.append(appearances)\n",
    "    #inputs.extend(centroids)\n",
    "    if data_format == 'channels_first':\n",
    "        img_shape = (2, X.shape[channel_axis], crop_dim, crop_dim)\n",
    "    else:\n",
    "        img_shape = (2, crop_dim, crop_dim, X.shape[channel_axis])\n",
    "        \n",
    "    data_shape = (2, 2,) # shape of centroid data\n",
    "\n",
    "    batch_x_1 = np.zeros(img_shape, dtype=K.floatx())\n",
    "    batch_x_2 = np.zeros(img_shape, dtype=K.floatx())\n",
    "    centroid_1 = np.zeros(data_shape, dtype=K.floatx())\n",
    "    centroid_2 = np.zeros(data_shape, dtype=K.floatx())\n",
    "    \n",
    "    batch_x_1[0] = appearances[0]\n",
    "    batch_x_2[0] = appearances[1]\n",
    "    \n",
    "    centroid_1[0] = np.array(centroids[0])\n",
    "    centroid_2[0] = np.array(centroids[1])\n",
    "    print(centroids)\n",
    "    return [batch_x_1, batch_x_2, centroid_1, centroid_2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1], [2, 1], [3, 1], [4, 1], [5, 1], [6, 1], [7, 1], [8, 1], [9, 1], [10, 1], [1, 2], [2, 2], [3, 2], [4, 2], [5, 2], [6, 2], [7, 2], [8, 2], [9, 2], [10, 2], [1, 3], [2, 3], [3, 3], [4, 3], [5, 3], [6, 3], [7, 3], [8, 3], [9, 3], [10, 3], [1, 4], [2, 4], [3, 4], [4, 4], [5, 4], [6, 4], [7, 4], [8, 4], [9, 4], [10, 4], [1, 5], [2, 5], [3, 5], [4, 5], [5, 5], [6, 5], [7, 5], [8, 5], [9, 5], [10, 5], [1, 6], [2, 6], [3, 6], [4, 6], [5, 6], [6, 6], [7, 6], [8, 6], [9, 6], [10, 6], [1, 7], [2, 7], [3, 7], [4, 7], [5, 7], [6, 7], [7, 7], [8, 7], [9, 7], [10, 7], [1, 8], [2, 8], [3, 8], [4, 8], [5, 8], [6, 8], [7, 8], [8, 8], [9, 8], [10, 8], [1, 9], [2, 9], [3, 9], [4, 9], [5, 9], [6, 9], [7, 9], [8, 9], [9, 9], [10, 9], [1, 10], [2, 10], [3, 10], [4, 10], [5, 10], [6, 10], [7, 10], [8, 10], [9, 10], [10, 10]]\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 8, 8, 64)     112448      input_21[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 4096)         0           sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 4096)         0           sequential_6[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 4098)         0           flatten_9[0][0]                  \n",
      "                                                                 input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 4098)         0           flatten_10[0][0]                 \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 8196)         0           concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          1049216     concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 128)          512         dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 128)          0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 128)          16512       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 128)          512         dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 128)          0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 3)            387         activation_30[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,179,587\n",
      "Trainable params: 1,178,563\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "weights loaded :)\n"
     ]
    }
   ],
   "source": [
    "#from deepcell.model_zoo import siamese_model\n",
    "compairs = []\n",
    "for label in labels_in_second:\n",
    "    for y in labels_in_first:\n",
    "        compairs.append([y, label]) #while loop with flag to avoid checking for additional positives\n",
    "print(compairs)\n",
    "\n",
    "\"\"\"model\"\"\"\n",
    "model_fn = siamese_model\n",
    "model_name = \"2018-08-06_nuclear_movie_hela0_same__0.h5\"\n",
    "MODEL_DIR = \"/data/models\"\n",
    "PREFIX = \"cells/HeLa/S3/\"\n",
    "in_shape = (32, 32, 1)\n",
    "weights = os.path.join(MODEL_DIR, PREFIX, model_name)\n",
    "#n_features = 3...not used?!\n",
    "#window_size = (30, 30)\n",
    "\n",
    "run_siamese_model = model_fn(input_shape=in_shape)\n",
    "run_siamese_model.load_weights(weights)\n",
    "print(\"weights loaded :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label list:  [1, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [2, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.5/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [3, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [4, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [5, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [6, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [7, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [8, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [9, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [10, 1]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [1, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [2, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [3, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [4, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [5, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [6, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [7, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [8, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [9, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [10, 2]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [1, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [2, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [3, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [4, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [5, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [6, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [7, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [8, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [9, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [10, 3]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [1, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [2, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [3, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [4, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [5, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [6, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [7, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [8, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [9, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [10, 4]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [1, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [2, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [3, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [4, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [5, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [6, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [7, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [8, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [9, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [10, 5]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [1, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [2, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [3, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [4, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [5, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [6, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [7, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [8, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [9, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [10, 6]\n",
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [1, 7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appearances:  (2, 32, 32, 1)\n",
      "[[0.0000000e+00 1.0000000e+00 0.0000000e+00]\n",
      " [1.0352762e-03 9.9855036e-01 4.1435694e-04]]\n",
      "label list:  [2, 7]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d388d00758d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label list: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minto_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfirst_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#list_of_nuclear_weights = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 return format.read_array(bytes,\n\u001b[1;32m    234\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m                     \u001b[0mread_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_read_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                     \u001b[0mread_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"array data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m                     array[i:i+read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[1;32m    685\u001b[0m                                                              count=read_count)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;31m# done about that.  note that regular files can't be non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_left\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_crc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/zipfile.py\u001b[0m in \u001b[0;36m_update_crc\u001b[0;34m(self, newdata)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0;31m# No need to compute the CRC if we don't have a reference value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_crc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_crc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;31m# Check the CRC if we're at the end of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_running_crc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expected_crc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_outputs = []\n",
    "\n",
    "for i in range(len(compairs)):\n",
    "    print(\"label list: \", compairs[i])\n",
    "    into_model = get_inputs(data['X'][segment], data['y'][segment], [first_f, second_f], compairs[i], crop_dim = 32)\n",
    "\n",
    "    #list_of_nuclear_weights = []\n",
    "    #for j in xrange(1):\n",
    "    #nuclear_weights = os.path.join(trained_network_nuclear_directory,  nuclear_prefix + str(j) + \".h5\")\n",
    "    #list_of_nuclear_weights += [nuclear_weights]\n",
    "    model_output = run_siamese_model.predict(into_model)\n",
    "    print(\"output: \", model_output.shape)\n",
    "    print(model_output)\n",
    "    model_outputs.append(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_siamese(image, model, win_x=30, win_y=30, split=True):\n",
    "    channel_axis = 1 if CHANNELS_FIRST else -1\n",
    "    n_features = model.layers[-1].output_shape[channel_axis]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
